# api-and-web-data-scraping-project
This project is focused on web scraping and data extraction from online news articles, specifically from the New York Times website. The main objectives are to gather article headlines, summaries, and associated metadata, and to store this information in a structured format for further analysis.

## Project Structure
- `web-scraping.ipynb`: Jupyter Notebook containing the web scraping code and data processing logic.
- `ny_times_articles.csv`: CSV file containing the extracted article data.

## Technologies Used
- Python
- BeautifulSoup
- Pandas
- Requests

## Getting Started
1. Clone the repository:
   ```
   git clone https://github.com/yourusername/api-and-web-data-scraping-project.git
   ```
2. Navigate to the project directory:
   ```
   cd api-and-web-data-scraping-project
   ```
3. Install the required packages:
   ```
   pip install -r requirements.txt
   ```
4. Run the Jupyter Notebook:
   ```
   jupyter notebook web-scraping.ipynb
   ```

## Usage
- The notebook contains code to scrape the New York Times homepage for article headlines and summaries.
- The extracted data is saved to a CSV file for easy access and analysis.

## Contributing
Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.